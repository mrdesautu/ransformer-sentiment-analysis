# GuÃ­a de MLflow para Sentiment Analysis

Esta guÃ­a explica cÃ³mo usar MLflow para rastrear experimentos, hiperparÃ¡metros y mÃ©tricas durante el entrenamiento de modelos.

## ğŸ¯ Â¿QuÃ© trackea MLflow automÃ¡ticamente?

### HiperparÃ¡metros registrados:
- **Modelo**: `model_name`, `num_labels`, `max_length`, `model_parameters`, `model_size_mb`
- **Entrenamiento**: `learning_rate`, `batch_size_train`, `batch_size_eval`, `num_epochs`, `weight_decay`
- **Datos**: `dataset_name`, `train_size`, `eval_size`, `test_size`

### MÃ©tricas registradas:
- **Durante entrenamiento** (cada logging_step): `loss`, `eval_loss`, `eval_accuracy`, `eval_f1`, etc.
- **MÃ©tricas finales**: `test_loss`, `test_accuracy`, `test_f1`, `test_precision`, `test_recall`

### Artefactos guardados:
- Modelo entrenado completo (PyTorch)
- GrÃ¡fico de historial de entrenamiento (`training_history.png`)
- Archivo de configuraciÃ³n (`config.json`)

---

## ğŸš€ Uso bÃ¡sico

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Entrenar con MLflow (habilitado por defecto)
```bash
python -m src.train --config config.json --output_dir ./my_model
```

### 3. Entrenar con nombre de experimento personalizado
```bash
python -m src.train \
  --config config.json \
  --output_dir ./my_model \
  --experiment-name "distilbert-imdb-experiment" \
  --run-name "run-lr-3e5"
```

### 4. Entrenar sin MLflow (si es necesario)
```bash
python -m src.train --config config.json --output_dir ./my_model --no-mlflow
```

---

## ğŸ“Š Ver experimentos en la UI de MLflow

### Iniciar la UI de MLflow:
```bash
mlflow ui
```

Luego abre tu navegador en: **http://localhost:5000**

### Especificar ubicaciÃ³n personalizada de mlruns:
```bash
mlflow ui --backend-store-uri ./mlruns
```

---

## ğŸ”§ ConfiguraciÃ³n avanzada

### Usar servidor remoto de MLflow

1. Configurar variables de entorno:
```bash
export MLFLOW_TRACKING_URI="http://your-mlflow-server:5000"
export MLFLOW_EXPERIMENT_NAME="production-sentiment-model"
```

2. Entrenar:
```bash
python -m src.train --config config.json --output_dir ./my_model
```

### Configurar desde cÃ³digo (mlflow_config.py)

```python
from mlflow_config import setup_mlflow

# Configurar tracking URI y experimento
setup_mlflow(
    tracking_uri="http://localhost:5000",
    experiment_name="my-custom-experiment",
    artifact_location="s3://my-bucket/mlflow-artifacts"
)
```

---

## ğŸ“ˆ Comparar experimentos

En la UI de MLflow puedes:

1. **Ver todas las corridas** de un experimento
2. **Comparar hiperparÃ¡metros** entre diferentes runs
3. **Visualizar mÃ©tricas** en grÃ¡ficos interactivos
4. **Descargar modelos** guardados
5. **Registrar modelos** en el Model Registry

### Ejemplo: Comparar learning rates

Ejecuta varios entrenamientos con diferentes learning rates:

```bash
# Run 1: lr=2e-5
python -m src.train --config config.json --run-name "lr-2e5"

# Run 2: lr=3e-5
# (Modifica config.json con "learning_rate": 3e-5)
python -m src.train --config config.json --run-name "lr-3e5"

# Run 3: lr=5e-5
# (Modifica config.json con "learning_rate": 5e-5)
python -m src.train --config config.json --run-name "lr-5e5"
```

Luego en la UI selecciona las 3 corridas y haz clic en "Compare".

---

## ğŸ—‚ï¸ Estructura de MLflow

```
mlruns/
â”œâ”€â”€ 0/                          # Experimento por defecto
â”‚   â””â”€â”€ meta.yaml
â”œâ”€â”€ 1/                          # Experimento "sentiment-analysis-training"
â”‚   â”œâ”€â”€ meta.yaml
â”‚   â”œâ”€â”€ <run-id-1>/
â”‚   â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â”‚   â”œâ”€â”€ model/         # Modelo PyTorch guardado
â”‚   â”‚   â”‚   â”œâ”€â”€ training_history.png
â”‚   â”‚   â”‚   â””â”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ metrics/           # MÃ©tricas por step
â”‚   â”‚   â”œâ”€â”€ params/            # HiperparÃ¡metros
â”‚   â”‚   â””â”€â”€ tags/
â”‚   â””â”€â”€ <run-id-2>/
â”‚       â””â”€â”€ ...
â””â”€â”€ models/                     # Model Registry
```

---

## ğŸ“ Mejores prÃ¡cticas

### 1. Usa nombres descriptivos
```bash
python -m src.train \
  --run-name "distilbert-imdb-4k-lr2e5-bs8" \
  --experiment-name "sentiment-imdb-experiments"
```

### 2. Documenta tus runs con tags
Puedes agregar tags programÃ¡ticamente en `src/train.py`:
```python
mlflow.set_tag("git_commit", "abc123")
mlflow.set_tag("author", "tu-nombre")
mlflow.set_tag("purpose", "baseline-experiment")
```

### 3. Versiona tus experimentos
- Crea experimentos separados para diferentes datasets o arquitecturas
- Usa run names consistentes para facilitar bÃºsquedas

### 4. Guarda artefactos adicionales
```python
# En src/train.py, puedes agregar:
mlflow.log_artifact("confusion_matrix.png")
mlflow.log_dict({"vocab_size": 30000}, "model_metadata.json")
```

---

## ğŸ” Buscar y filtrar runs

### En la UI de MLflow:

1. **Filtrar por mÃ©trica**:
   ```
   metrics.test_accuracy > 0.90
   ```

2. **Filtrar por parÃ¡metro**:
   ```
   params.learning_rate = "2e-5"
   ```

3. **Filtrar por nombre**:
   ```
   attributes.run_name LIKE '%distilbert%'
   ```

4. **Combinar filtros**:
   ```
   metrics.test_accuracy > 0.90 AND params.num_epochs = "3"
   ```

---

## ğŸš¢ Model Registry (producciÃ³n)

### Registrar un modelo desde la UI:
1. Abre un run exitoso
2. En la secciÃ³n "Artifacts", haz clic en el modelo
3. Click en "Register Model"
4. Elige un nombre (ej: `sentiment-model-production`)

### Registrar desde cÃ³digo:
```python
# Ya implementado en src/train.py
mlflow.pytorch.log_model(
    model, 
    "model",
    registered_model_name="sentiment-model-production"
)
```

### Transicionar modelos entre stages:
- **None** â†’ **Staging** â†’ **Production** â†’ **Archived**

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()
client.transition_model_version_stage(
    name="sentiment-model-production",
    version=1,
    stage="Production"
)
```

---

## ğŸ› Troubleshooting

### Problema: "No experiments found"
**SoluciÃ³n**: Verifica que el directorio `mlruns/` existe o configura `MLFLOW_TRACKING_URI`.

### Problema: "Port 5000 already in use"
**SoluciÃ³n**: Usa un puerto diferente:
```bash
mlflow ui --port 5001
```

### Problema: MÃ©tricas no aparecen
**SoluciÃ³n**: Verifica que `use_mlflow=True` en `train_model()` y que no usaste `--no-mlflow`.

### Problema: Modelo muy grande para registrar
**SoluciÃ³n**: Usa artifact storage externo (S3, Azure Blob, GCS):
```bash
export MLFLOW_ARTIFACT_LOCATION="s3://my-bucket/mlflow"
```

---

## ğŸ“š Recursos adicionales

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)
- [MLflow Projects](https://mlflow.org/docs/latest/projects.html)

---

## ğŸ¯ Ejemplo completo de workflow

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Entrenar modelo baseline
python -m src.train \
  --config config.json \
  --output_dir ./models/baseline \
  --experiment-name "sentiment-analysis" \
  --run-name "baseline-distilbert"

# 3. Experimentar con hiperparÃ¡metros
# Edita config.json: learning_rate = 3e-5
python -m src.train \
  --config config.json \
  --output_dir ./models/lr-3e5 \
  --experiment-name "sentiment-analysis" \
  --run-name "experiment-lr-3e5"

# 4. Iniciar UI de MLflow
mlflow ui

# 5. Abrir navegador en http://localhost:5000
# 6. Comparar runs, seleccionar el mejor modelo
# 7. Registrar modelo ganador en Model Registry
```

---

Â¡Ahora tienes un sistema completo de tracking de experimentos! ğŸ‰
