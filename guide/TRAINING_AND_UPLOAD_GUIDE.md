# üöÄ Gu√≠a Completa: Entrenar y Subir Modelo a Hugging Face

## üìã Proceso Completo

### Paso 1: Entrenar el Modelo

#### Opci√≥n A: Entrenamiento r√°pido (prueba)
```bash
python -m src.train \
  --config config_rapido.json \
  --output_dir ./quick_model \
  --run-name "quick-test" \
  --experiment-name "experiments"
```

#### Opci√≥n B: Entrenamiento completo (producci√≥n)
```bash
python -m src.train \
  --config config.json \
  --output_dir ./trained_model \
  --run-name "production-v1" \
  --experiment-name "production-training"
```

**Tiempo estimado:**
- CPU: 30-60 minutos (config.json)
- CPU: 5-10 minutos (config_rapido.json)
- GPU: 10-15 minutos (config.json)

---

### Paso 2: Verificar Resultados en MLflow

Mientras el modelo entrena, abre otra terminal:

```bash
mlflow ui
```

Luego abre: http://localhost:5000

**Qu√© ver√°s:**
- ‚úÖ Experimento "production-training"
- ‚úÖ Run "production-v1"
- ‚úÖ Hiperpar√°metros registrados
- ‚úÖ M√©tricas en tiempo real
- ‚úÖ Gr√°ficos de training
- ‚úÖ Modelo guardado

---

### Paso 3: Revisar el Modelo Entrenado

Una vez completado el entrenamiento, revisa:

```bash
ls -lah ./trained_model/
```

**Archivos generados:**
```
trained_model/
‚îú‚îÄ‚îÄ config.json                 # Configuraci√≥n del modelo
‚îú‚îÄ‚îÄ model.safetensors          # Pesos del modelo
‚îú‚îÄ‚îÄ tokenizer_config.json      # Configuraci√≥n del tokenizer
‚îú‚îÄ‚îÄ vocab.txt                  # Vocabulario
‚îú‚îÄ‚îÄ special_tokens_map.json    # Tokens especiales
‚îú‚îÄ‚îÄ model_info.json           # M√©tricas y metadatos
‚îú‚îÄ‚îÄ training_history.png      # Gr√°fico de entrenamiento
‚îî‚îÄ‚îÄ README.md                 # (se crear√° al subir a HF)
```

**Ver m√©tricas:**
```bash
cat ./trained_model/model_info.json
```

---

### Paso 4: Probar el Modelo Localmente

```python
from transformers import pipeline

# Cargar modelo local
classifier = pipeline(
    "sentiment-analysis", 
    model="./trained_model"
)

# Probar
result = classifier("This movie is absolutely amazing!")
print(result)
# [{'label': 'POSITIVE', 'score': 0.9998}]

result = classifier("I hated this product, waste of money.")
print(result)
# [{'label': 'NEGATIVE', 'score': 0.9995}]
```

---

### Paso 5: Autenticarse en Hugging Face

#### Opci√≥n A: CLI (recomendado)
```bash
huggingface-cli login
```

Te pedir√° tu token. Puedes obtenerlo en:
https://huggingface.co/settings/tokens

#### Opci√≥n B: Token directo
Guarda tu token para usar con el script de upload.

---

### Paso 6: Subir a Hugging Face

```bash
python upload_to_huggingface.py \
  --model-dir ./trained_model \
  --repo-name distilbert-sentiment-imdb
```

**Con opciones adicionales:**
```bash
python upload_to_huggingface.py \
  --model-dir ./trained_model \
  --repo-name distilbert-sentiment-imdb \
  --organization tu-organizacion \
  --private
```

**Qu√© hace el script:**
1. ‚úÖ Valida autenticaci√≥n de HF
2. ‚úÖ Crea repositorio (si no existe)
3. ‚úÖ Genera Model Card autom√°tico con m√©tricas
4. ‚úÖ Sube todos los archivos del modelo
5. ‚úÖ Muestra URL del modelo publicado

---

### Paso 7: Verificar en Hugging Face

Una vez subido, ve a:
```
https://huggingface.co/TU_USERNAME/distilbert-sentiment-imdb
```

**Deber√≠as ver:**
- ‚úÖ Model Card con m√©tricas
- ‚úÖ Archivos del modelo
- ‚úÖ Widget de inferencia (puedes probar el modelo directamente)
- ‚úÖ Ejemplos de c√≥digo

---

### Paso 8: Usar el Modelo desde Hugging Face

Una vez publicado, cualquiera puede usarlo:

```python
from transformers import pipeline

# Cargar desde HF Hub
classifier = pipeline(
    "sentiment-analysis", 
    model="TU_USERNAME/distilbert-sentiment-imdb"
)

# Usar
result = classifier("I love this!")
print(result)
```

---

## üéØ Flujo Completo (Comandos Secuenciales)

```bash
# 1. Entrenar modelo
python -m src.train \
  --config config.json \
  --output_dir ./trained_model \
  --run-name "production-v1"

# 2. Ver m√©tricas (en otra terminal)
mlflow ui

# 3. Probar localmente
python -c "
from transformers import pipeline
clf = pipeline('sentiment-analysis', model='./trained_model')
print(clf('Amazing product!'))
"

# 4. Login a HF
huggingface-cli login

# 5. Subir a HF
python upload_to_huggingface.py \
  --model-dir ./trained_model \
  --repo-name distilbert-sentiment-imdb

# 6. Probar desde HF
python -c "
from transformers import pipeline
clf = pipeline('sentiment-analysis', model='TU_USERNAME/distilbert-sentiment-imdb')
print(clf('Amazing product!'))
"
```

---

## üìä Entrenamiento en Progreso

### C√≥mo saber si est√° entrenando correctamente:

**Se√±ales buenas ‚úÖ:**
- Loss disminuye con cada epoch
- Accuracy aumenta
- No hay errores en la consola
- MLflow muestra m√©tricas actualiz√°ndose

**Se√±ales de problemas ‚ùå:**
- Loss no cambia (stuck)
- Accuracy ~0.50 (random)
- Errores de memoria (OOM)
- Entrenamiento muy lento

### Si el entrenamiento es muy lento en CPU:

1. **Usar config_rapido.json:**
   ```bash
   python -m src.train --config config_rapido.json --output_dir ./quick_model
   ```

2. **Reducir datos a√∫n m√°s:**
   Edita `config.json`:
   ```json
   "data": {
     "train_size": 1000,
     "eval_size": 200,
     "test_size": 100
   }
   ```

3. **Reducir √©pocas:**
   ```json
   "training": {
     "num_train_epochs": 2
   }
   ```

---

## üîç Monitoreo Durante Entrenamiento

### Ver logs en tiempo real:

El entrenamiento muestra:
```
Epoch 1/3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 250/500 [15:23<15:22, 3.69s/it]
  loss: 0.3245
  eval_loss: 0.2876
  eval_accuracy: 0.8750
```

### Interpretar m√©tricas:

- **loss**: Qu√© tan "equivocado" est√° el modelo (‚Üì mejor)
- **eval_loss**: Loss en validation set (‚Üì mejor)
- **eval_accuracy**: % de aciertos en validation (‚Üë mejor)

**Meta para buen modelo:**
- Loss final: < 0.3
- Accuracy final: > 0.85

---

## üí° Mejores Pr√°cticas

### 1. Versiona tus modelos
```bash
# Versi√≥n 1
python upload_to_huggingface.py \
  --model-dir ./trained_model \
  --repo-name distilbert-sentiment-v1

# Versi√≥n 2 (despu√©s de mejorar)
python upload_to_huggingface.py \
  --model-dir ./trained_model_v2 \
  --repo-name distilbert-sentiment-v2
```

### 2. Nombre descriptivo
Incluye informaci√≥n clave en el nombre:
- Modelo base: `distilbert`, `bert`, `roberta`
- Tarea: `sentiment`, `classification`
- Dataset: `imdb`, `amazon`, etc.
- Versi√≥n: `v1`, `v2`

Ejemplos:
- `distilbert-sentiment-imdb-v1`
- `bert-base-sentiment-amazon`
- `roberta-sentiment-multilingual`

### 3. Documenta en Model Card
El script genera autom√°ticamente, pero puedes editar despu√©s en HF:
- Agrega ejemplos de uso
- Limitaciones conocidas
- Casos de uso recomendados

### 4. Privacidad
Para modelos experimentales:
```bash
python upload_to_huggingface.py \
  --model-dir ./trained_model \
  --repo-name my-experimental-model \
  --private
```

---

## üêõ Troubleshooting

### Error: "Authentication required"
```bash
# Soluci√≥n:
huggingface-cli login
# O provee token:
python upload_to_huggingface.py --model-dir ./model --repo-name my-model --token YOUR_TOKEN
```

### Error: "Repository already exists"
**No es problema.** El script actualiza el repo existente.

### Error: "Model files not found"
Verifica que el directorio tenga los archivos necesarios:
```bash
ls ./trained_model/
# Debe contener: model.safetensors, config.json, tokenizer files
```

### Modelo sube pero no funciona en HF
Verifica que el `model_info.json` se gener√≥ correctamente:
```bash
cat ./trained_model/model_info.json
```

---

## ‚úÖ Checklist Final

Antes de subir a producci√≥n:

- [ ] Modelo entrenado sin errores
- [ ] M√©tricas > 85% accuracy
- [ ] Probado localmente y funciona
- [ ] Model Card completo
- [ ] Nombre descriptivo
- [ ] Ejemplos de uso documentados
- [ ] Subido a HF exitosamente
- [ ] Probado desde HF (pip install transformers y usar)

---

## üìö Recursos

- **Hugging Face Hub Docs:** https://huggingface.co/docs/hub/
- **Model Card Guide:** https://huggingface.co/docs/hub/model-cards
- **Transformers Docs:** https://huggingface.co/docs/transformers/

---

**√öltima actualizaci√≥n:** 24 de octubre de 2025  
**Estado actual:** Entrenamiento en progreso... ‚è≥
